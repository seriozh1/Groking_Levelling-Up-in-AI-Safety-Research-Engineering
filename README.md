# AI Safety Research Engineering Progress Tracker

This repository tracks my progress through the [**Levelling Up in AI Safety Research Engineering**](https://www.lesswrong.com/posts/uLstPRyYwzfrx3enG/levelling-up-in-ai-safety-research-engineering) guide by Thomas Woodside, as published on LessWrong. The guide provides a structured, level-based path to develop skills in AI Safety Research Engineering, with objectives, concrete goals, and recommended resources for each level. This README lists all materials from the guide, organized by level, with checkboxes to mark completion.

## Purpose

The goal is to systematically work through the resources and objectives outlined in the guide, documenting my progress in AI Safety Research Engineering. Each level includes specific materials (e.g., courses, books, papers, exercises) that I will complete, with checkboxes to track my advancement.

## Levels and Materials

### Level 1: AI Safety Fundamentals

**Objective**: Learn the basics of why AI Safety is important and decide whether to pursue a theoretical or empirical path.  
**Goals**:  
- Read foundational materials on AI Safety.  
- Engage with arguments for AI Safety to test personal fit.  
- Optionally, start exploring machine learning basics.  
- Complete an AI Safety introductory reading group fellowship.  
- Write a reflection on an AI Safety topic and share it for feedback.  
- Decide if you want to continue with AI Safety Research Engineering or explore other fields like Theoretical AI Alignment or AI Policy.

**Resources**:  
- [ ] *Existential Risk from Artificial Intelligence* by Toby Ord (Chapter from *The Precipice*)  
- [ ] *Superintelligence* by Nick Bostrom  
- [ ] *Human Compatible* by Stuart Russell  
- [ ] Alignment Forum posts (e.g., *The Alignment Problem* by Brian Christian, or similar introductory posts)  
- [ ] LessWrong posts on AI Safety (e.g., *AI Safety FAQ* or equivalent introductory articles)  
- [ ] 80,000 Hours AI Safety career profile  
- [ ] AGI Safety Fundamentals Alignment Curriculum  
- [ ] STS 10SI: Intro to AI Alignment  
- [ ] CUEA Standard AI Safety Reading Group Syllabus - Columbia EA  
- [ ] Intro to ML Safety Course - CAIS  
- [ ] AGI safety from first principles - Richard Ngo  
- [ ] AI Alignment Forum  
- [ ] Alignment Newsletter - Rohin Shah  

### Level 2: Machine Learning Fundamentals

**Objective**: Gain a solid foundation in machine learning concepts, basic implementation skills, and essential software engineering skills.  
**Goals**:  
- Understand core ML concepts (e.g., supervised/unsupervised learning, neural networks).  
- Implement simple ML models using Python and libraries like TensorFlow or PyTorch.  
- Complete introductory ML courses and exercises.  
- Solve basic algorithmic programming problems with Python.  
- Know scientific computing basics (e.g., NumPy, Jupyter Notebooks).  
- Create and manage a Git repository on GitHub for a personal project.  
- Learn command line, documentation, and unit testing basics.  

**Software Engineering Skills**:  
- [ ] Python Programming: Choose 1-2 from [www.learnpython.org](https://www.learnpython.org), [Learn Python 3 - Codecademy](https://www.codecademy.com/learn/learn-python-3), [Scientific Computing with Python Certification - freeCodeCamp](https://www.freecodecamp.org/learn/scientific-computing-with-python/), [CS50's Introduction to Programming with Python - Harvard University](https://cs50.harvard.edu/python/2022/)  
- [ ] Scientific Python: Choose 1-2 from [Data Analysis with Python Certification - freeCodeCamp](https://www.freecodecamp.org/learn/data-analysis-with-python/), [Learn Python for Data Science, Structures, Algorithms, Interviews - Udemy](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/)  
- [ ] Command Line: Choose 1-3 from [Learning the shell - LinuxCommand.org](http://linuxcommand.org/lc3_learning_the_shell.php), [Linux Command Line Basics - Udacity](https://www.udacity.com/course/linux-command-line-basics--ud595), [The Unix Shell - software carpentries](https://swcarpentry.github.io/shell-novice/)  
- [ ] Git/GitHub: Choose 2+ from [GitHub Tutorial - Beginner's Training Guide - Anson Alexander](https://www.youtube.com/watch?v=3RjQznt-8kE), [Git Immersion](https://gitimmersion.com/), [GitHub Skills](https://skills.github.com/), [Version Control with Git - software carpentries](https://swcarpentry.github.io/git-novice/), [first-contributions](https://github.com/firstcontributions/first-contributions)  
- [ ] Documentation: Choose 1-2 from [Documenting Python Code: A Complete Guide - Real Python](https://realpython.com/documenting-python-code/), [Documenting Python Code: How to Guide - DataCamp](https://www.datacamp.com/tutorial/docstrings-python)  
- [ ] Unit Testing: Choose 1-3 from [Getting Started With Testing in Python - Real Python](https://realpython.com/python-testing/), [A Gentle Introduction to Unit Testing in Python - Machine Learning Mastery](https://machinelearningmastery.com/a-gentle-introduction-to-unit-testing-in-python/), [Unit Testing in Python Tutorial - DataCamp](https://www.datacamp.com/tutorial/unit-testing-python)  

**Foundational Mathematics**:  
- [ ] Basic Calculus: [Essence of calculus - 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)  
- [ ] Probability: Choose 1 from [Probability - The Science of Uncertainty and Data - MIT](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/), [Introduction to Probability - Harvard](https://pll.harvard.edu/course/introduction-probability), [Part I: The Fundamentals | Introduction to Probability - MIT OpenCourseWare](https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/)  
- [ ] Linear Algebra: Choose 1 from [Essence of linear algebra - 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab), [Linear Algebra - MIT OpenCourseWare](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/), [Georgia Techâ€™s course](https://textbooks.math.gatech.edu/ila/), [Linear Algebra - Foundations to Frontiers - edX](https://www.edx.org/course/linear-algebra-foundations-to-frontiers), [Linear Algebra Done Right - Sheldon Axler](https://linear.axler.net/)  
- [ ] Multivariable Calculus: Choose 1 from [Multivariable Calculus - MIT OpenCourseWare](https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/), [Multivariable Calculus - Khan Academy](https://www.khanacademy.org/math/multivariable-calculus), [The Matrix Calculus You Need For Deep Learning - explained.ai](https://explained.ai/matrix-calculus/), [Mathematics for Machine Learning - Imperial College London](https://www.coursera.org/learn/mathematics-for-machine-learning-linear-algebra)  

**Machine Learning Resources**:  
- [ ] *Deep Learning* by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (selected chapters on fundamentals)  
- [ ] Coursera *Machine Learning* by Andrew Ng  
- [ ] Fast.ai *Practical Deep Learning for Coders*  
- [ ] Kaggle introductory ML courses (e.g., *Intro to Machine Learning*, *Intermediate Machine Learning*)  
- [ ] *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by AurÃ©lien GÃ©ron (selected chapters)  
- [ ] Coding exercises: Implement a simple neural network from scratch  
- [ ] Kaggle competitions (e.g., Titanic dataset, digit recognizer)  

### Level 3: Advanced Machine Learning

**Objective**: Deepen ML knowledge, gain practical experience with advanced models and frameworks, and understand transformers.  
**Goals**:  
- Master advanced ML techniques (e.g., CNNs, RNNs, GANs).  
- Work on complex ML projects using frameworks like PyTorch or TensorFlow.  
- Understand optimization, regularization, and model evaluation.  
- Gain a principled understanding of the transformer architecture and implement a basic transformer model.  

**Resources**:  
- [ ] *Deep Learning* by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (advanced chapters)  
- [ ] Coursera *Deep Learning Specialization* by Andrew Ng  
- [ ] Fast.ai *Deep Learning from the Foundations*  
- [ ] *Dive into Deep Learning* by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola  
- [ ] PyTorch or TensorFlow tutorials (e.g., official documentation, online tutorials)  
- [ ] Kaggle advanced competitions (e.g., image classification, NLP tasks)  
- [ ] Coding exercises: Implement a CNN or RNN for a specific task (e.g., image classification, text generation)  
- [ ] Blog posts on advanced ML topics (e.g., Distill.pub articles on neural network architectures)  

**Sub-field Specialization (Optional)**:  
Choose a sub-field like NLP, CV, or RL and complete 1-2 resources:  
- **NLP**: [Stanford CS 224N](http://web.stanford.edu/class/cs224n/), [CS224U - Stanford](https://web.stanford.edu/class/cs224u/), [A Code-First Introduction to NLP - fast.ai](https://www.fast.ai/2019/07/08/fastai-nlp/)  
- **CV**: [Deep Learning for Computer Vision - UMich](https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2020/), [CS231n - Stanford](http://cs231n.stanford.edu/)  
- **RL**: [Spinning Up in Deep RL - OpenAI](https://spinningup.openai.com/en/latest/), [Deep RL Class - Hugging Face](https://huggingface.co/deep-rl-course/unit0/introduction), [CS 285 - UC Berkeley](http://rail.eecs.berkeley.edu/deeprlcourse/)  

**Understanding Transformers**:  
- [ ] Experiment with deployed transformers: [OpenAI Playground](https://beta.openai.com/playground), [Elicit](https://elicit.org/), [DALLÂ·E 2](https://openai.com/dall-e-2/), [Codex](https://openai.com/blog/openai-codex/)  
- [ ] Study the transformer architecture: [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Sections 1-3), [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), [Formal Algorithms for Transformers - DeepMind](https://arxiv.org/abs/2207.09238)  
- [ ] Use ðŸ¤— Transformers: [Hugging Face Course](https://huggingface.co/course/chapter1)  
- [ ] Implement transformers from scratch: [MLAB-Transformers-From-Scratch - Redwood Research](https://github.com/redwoodresearch/mlab-transformers-from-scratch), [deep_learning_curriculum/1-Transformers - Jacob Hilton](https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md)  

### Level 4: AI Safety Research Engineering

**Objective**: Apply ML skills to AI Safety problems, understand safety-specific research, and contribute to empirical work by reimplementing papers.  
**Goals**:  
- Read and summarize AI Safety research papers.  
- Reproduce results from AI Safety experiments.  
- Contribute to open-source AI Safety projects or implement safety-related algorithms.  
- Reimplement the key contributions of 5+ AI research papers.  

**Resources**:  
- [ ] *Post-hoc Interpretability for Neural NLP: A Survey* by Madsen et al.  
- [ ] *Locating and Editing Factual Associations in GPT (ROME)* by Meng et al.  
- [ ] *Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift* by Baek et al.  
- [ ] Alignment Forum posts on interpretability and robustness (e.g., *Mechanistic Interpretability* series)  
- [ ] LessWrong posts on AI Safety engineering (e.g., *Redwood Research* project summaries)  
- [ ] Open-source AI Safety projects (e.g., Redwood Research, Anthropicâ€™s interpretability work)  
- [ ] Coding exercises: Reproduce a simple interpretability experiment (e.g., visualizing attention in a transformer)  
- [ ] Write a blog post summarizing an AI Safety paper or experiment  

**Reading and Implementing Papers**:  
- [ ] How to read papers: [How to Read a Paper - S. Keshav](http://ccr.sigcomm.org/online/files/p83-keshavA.pdf), [How to Read Research Papers - NVIDIA](https://developer.nvidia.com/blog/how-to-read-research-papers-a-pragmatic-approach-for-ml-practitioners/)  
- [ ] How to implement papers: [Lessons Learned Reproducing a Deep RL Paper - Amid Fish](https://amid.fish/reproducing-deep-rl), [Advice on paper replication - Richard Ngo](https://www.alignmentforum.org/posts/2fCvdP4YnW9X6vA7x/advice-on-paper-replication)  
- [ ] Implement 5+ papers (e.g., from [Machine Learning Reading List - Ought](https://ought.org/research/reading-list), [Interpretability: Circuits - Olah et al.](https://distill.pub/2020/circuits/))  

### Level 5: Advanced AI Safety Research

**Objective**: Generate novel AI Safety research questions, design experiments, and potentially transition to Research Scientist roles.  
**Goals**:  
- Formulate original research questions in AI Safety.  
- Design and execute empirical experiments to test hypotheses.  
- Apply for AI Safety residencies, Ph.D. programs, or research roles.  
- Create 5+ concrete research questions and conduct research to share results.  

**Resources**:  
- [ ] *Post-hoc Interpretability for Neural NLP: A Survey* by Madsen et al. (revisited for deeper analysis)  
- [ ] *Locating and Editing Factual Associations in GPT (ROME)* by Meng et al. (revisited for experimental design)  
- [ ] *Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift* by Baek et al. (revisited for research question formulation)  
- [ ] Alignment Forum posts on advanced safety topics (e.g., *Scalable Alignment* or *Robustness* series)  
- [ ] LessWrong posts on novel AI Safety research (e.g., *Anthropicâ€™s Research Agenda* summaries)  
- [ ] Research exercises: Design an experiment to test a hypothesis in interpretability or robustness  
- [ ] Write a research proposal or paper draft on an AI Safety topic  
- [ ] Apply to AI Safety residencies (e.g., Anthropic, DeepMind Safety, Redwood Research)  
- [ ] Explore Ph.D. programs in AI Safety or related fields  

**Research Advice and Open Questions**:  
- [ ] Research advice: [Research Taste Exercises - Chris Olah](https://distill.pub/2019/research-taste-exercises/), [How I Formed My Own Views About AI Safety - Neel Nanda](https://www.neelnanda.io/blog/how-i-formed-my-views-on-ai-safety)  
- [ ] Open questions: [AI Safety Ideas - Apart Research](https://aisafetyideas.com/), [Open Problems in AI X-Risk - CAIS](https://www.safe.ai/open-problems), [Random, Assorted AI Safety Ideas - Evan Hubinger](https://www.alignmentforum.org/posts/4bGWR6nMno6J6u3oM/random-assorted-ai-safety-ideas)  

## Notes

- **Progress Tracking**: Checkboxes will be marked (`- [x]`) as I complete each resource. Progress updates may be committed to this repository.  
- **Resources**: Some resources (e.g., Alignment Forum posts, LessWrong posts) are broad categories. Iâ€™ll select specific, relevant posts and document them in the repository as I progress.  
- **Feedback**: Suggestions for additional resources or improvements to this tracker are welcome via GitHub issues.  
- **Risks and Considerations**:  
  - Be cautious of advancing AI capabilities unintentionally, especially at higher levels; consult trusted AI Safety researchers if unsure.  
  - Find mentors and peers for support to avoid isolation and burnout.  
  - Avoid early over-specialization by exploring broadly initially, and late over-generalization by deepening expertise later.  
  - Stay updated as AI and AI Safety evolve rapidly; revisit earlier levels as needed.  

## Acknowledgments

This README is based on the [**Levelling Up in AI Safety Research Engineering**](https://www.lesswrong.com/posts/uLstPRyYwzfrx3enG/levelling-up-in-ai-safety-research-engineering) guide by Thomas Woodside, cross-posted to the EA Forum. It also draws from:  
- [How to pursue a career in technical AI alignment - Charlie Rogers-Smith](https://www.alignmentforum.org/posts/2fCvdP4YnW9X6vA7x/how-to-pursue-a-career-in-technical-ai-alignment)  
- [deep_learning_curriculum - Jacob Hilton](https://github.com/jacobhilton/deep_learning_curriculum)  
- [ML Safety Scholars Program - CAIS](https://www.safe.ai/mlss)  
- [ML engineering for AI Safety & robustness - 80,000 Hours](https://80000hours.org/articles/ml-engineering-career/)  
- [ML for Alignment Bootcamp (MLAB 2) - Redwood Research](https://www.redwoodresearch.org/mlab)  
- [Machine Learning Reading List - Ought](https://ought.org/research/reading-list)  
- [Careers in alignment - Adam Gleave](https://www.adamgleave.me/careers-in-alignment/)  
- Discussions with AI Safety researchers  

Thanks to all contributors for shaping this path to skill up in AI Safety Research Engineering!
